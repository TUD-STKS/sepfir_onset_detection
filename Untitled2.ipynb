{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d2cb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 40/40 [00:10<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 40 files\n",
      "  Onsets:  3559 TP:  3081 FP:   485 FN:   478 Precision: 0.864 Recall: 0.866 F-measure: 0.865 mean:  -7.4 ms std:   9.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 41/41 [00:10<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 41 files\n",
      "  Onsets:  3220 TP:  2586 FP:   367 FN:   634 Precision: 0.876 Recall: 0.803 F-measure: 0.838 mean:  -5.4 ms std:  11.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 40/40 [00:09<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 40 files\n",
      "  Onsets:  2542 TP:  2089 FP:   451 FN:   453 Precision: 0.822 Recall: 0.822 F-measure: 0.822 mean:  -5.3 ms std:  11.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 40 files\n",
      "  Onsets:  2995 TP:  2581 FP:   387 FN:   414 Precision: 0.870 Recall: 0.862 F-measure: 0.866 mean:  -7.0 ms std:   8.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 40/40 [00:09<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 40 files\n",
      "  Onsets:  3915 TP:  3362 FP:   361 FN:   553 Precision: 0.903 Recall: 0.859 F-measure: 0.880 mean:  -6.0 ms std:  10.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 41/41 [00:09<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 41 files\n",
      "  Onsets:  2696 TP:  2330 FP:   275 FN:   366 Precision: 0.894 Recall: 0.864 F-measure: 0.879 mean:  -6.9 ms std:  10.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 40 files\n",
      "  Onsets:  2920 TP:  2585 FP:   299 FN:   335 Precision: 0.896 Recall: 0.885 F-measure: 0.891 mean:  -6.9 ms std:  10.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:11<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum for 39 files\n",
      "  Onsets:  3980 TP:  2865 FP:   286 FN:  1115 Precision: 0.909 Recall: 0.720 F-measure: 0.804 mean:  -5.9 ms std:  10.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform SUPERFLUX Onset detection on all folds\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import librosa\n",
    "import madmom\n",
    "from tqdm import tqdm\n",
    "from madmom.audio.signal import SignalProcessor, FramedSignalProcessor\n",
    "from madmom.audio.stft import ShortTimeFourierTransformProcessor\n",
    "from madmom.audio.spectrogram import (FilteredSpectrogramProcessor,\n",
    "                                      LogarithmicSpectrogramProcessor,\n",
    "                                      SpectrogramDifferenceProcessor)\n",
    "from madmom.features.onsets import OnsetPeakPickingProcessor\n",
    "from madmom.evaluation.onsets import OnsetEvaluation, OnsetSumEvaluation\n",
    "from madmom.processors import SequentialProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Feature extraction parameters\n",
    "sr = 44100               # Sampling rate\n",
    "fs = 2048                # Frame size\n",
    "fps = 200                # Frames per second\n",
    "window = np.hanning      # Hann-Window for STFT\n",
    "num_bands = 24           # Number of bands per octave\n",
    "f_min = 27.5             # Minimum frequency\n",
    "f_max = 16000            # Maximum frequency\n",
    "\n",
    "# Peak picking and evaluation parameters\n",
    "pre_max = 0.03      # Use pre_max seconds past information for moving maximum\n",
    "post_max = 0.03     # Use post_max seconds future information for moving maximum\n",
    "pre_avg = 0.1       # Use pre_avg seconds past information for moving average\n",
    "post_avg = 0.07     # Use post_avg seconds future information for moving average\n",
    "eval_window = 0.05  # Time window around a reference onset\n",
    "combine = 0.03      # Only report one onset within combine seconds\n",
    "delay = 0           # Report the detected onsets delay seconds delayed\n",
    "diff_max_bins = 3\n",
    "threshold = 1.3\n",
    "\n",
    "# Instantiate Processors with above parameters\n",
    "signal_proc = SignalProcessor(sample_rate=sr, num_channels=1, norm=True)\n",
    "frames_proc = FramedSignalProcessor(frame_size=fs, fps=fps)\n",
    "stft_proc = ShortTimeFourierTransformProcessor(window=window)\n",
    "fil_spec_proc = FilteredSpectrogramProcessor(num_bands=num_bands, fmin=f_min, fmax=f_max, norm_filters=False)\n",
    "logfil_spec_proc = LogarithmicSpectrogramProcessor()\n",
    "specDiffProc = SpectrogramDifferenceProcessor(diff_max_bins=diff_max_bins, positive_diffs=True)\n",
    "\n",
    "preprocessor = SequentialProcessor([signal_proc, frames_proc, stft_proc, fil_spec_proc, logfil_spec_proc])\n",
    "\n",
    "peak_proc = OnsetPeakPickingProcessor(threshold=threshold,\n",
    "                                      pre_max=pre_max,\n",
    "                                      post_max=post_max,\n",
    "                                      pre_avg=pre_avg,\n",
    "                                      post_avg=post_avg,\n",
    "                                      combine=combine,\n",
    "                                      delay=delay,\n",
    "                                      fps=fps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing(audiofile, sr, preprocessor):\n",
    "    # Load and normalize audio file\n",
    "    signal, sr = librosa.load(audiofile, sr=sr, mono=True)\n",
    "\n",
    "    # Calculate preprocessed spectrogram\n",
    "    log_filtered_spec = preprocessor.process(signal)\n",
    "    return log_filtered_spec\n",
    "\n",
    "def reduction_filtering(log_filtered_spec):\n",
    "    deriv = specDiffProc.process(log_filtered_spec)\n",
    "    odf = deriv.sum(axis=1)\n",
    "    return odf\n",
    "\n",
    "def peak_picking(odf, peakprocessor):\n",
    "    # Peak-Picking\n",
    "    onsets = peakprocessor.process(odf)\n",
    "    return onsets\n",
    "\n",
    "def evaluation(onsets, annotationsfile):\n",
    "    # Evaluation\n",
    "    # Load annotations\n",
    "    annotations = madmom.io.load_events(annotationsfile)\n",
    "    evl = OnsetEvaluation(detections=onsets,\n",
    "                          annotations=annotations,\n",
    "                          window=eval_window,\n",
    "                          combine=combine,\n",
    "                          delay=delay)\n",
    "    return evl\n",
    "\n",
    "\n",
    "def get_filenames_from_fold(fold):\n",
    "    path_to_folds = \"data/splits\"\n",
    "    with open(os.path.join(path_to_folds, fold)) as fd:\n",
    "            track_names = [line.rstrip() for line in fd]  # List containing all track names for a specific fold\n",
    "            fd.close()\n",
    "            return track_names\n",
    "\n",
    "\n",
    "fold0 = get_filenames_from_fold('8-fold_cv_random_0.fold')\n",
    "fold1 = get_filenames_from_fold('8-fold_cv_random_1.fold')\n",
    "fold2 = get_filenames_from_fold('8-fold_cv_random_2.fold')\n",
    "fold3 = get_filenames_from_fold('8-fold_cv_random_3.fold')\n",
    "fold4 = get_filenames_from_fold('8-fold_cv_random_4.fold')\n",
    "fold5 = get_filenames_from_fold('8-fold_cv_random_5.fold')\n",
    "fold6 = get_filenames_from_fold('8-fold_cv_random_6.fold')\n",
    "fold7 = get_filenames_from_fold('8-fold_cv_random_7.fold')\n",
    "\n",
    "test_folds = [ fold7, fold1, fold4, fold3, fold6, fold0, fold5, fold2 ] # Sort folds in correct order!!!\n",
    "df_list = []\n",
    "dict_fscores = []\n",
    "total_sum_evals = []\n",
    "# Iterate over all filter kernels and their corresponding test folds\n",
    "for i in range(0,8,1):\n",
    "    \n",
    "    track_names = test_folds[i]\n",
    "    list_evals = []\n",
    "    \n",
    "    dict_fscores = {}\n",
    "    # Iterate over all tracks in this fold and perform Onset detection with evaluations\n",
    "    for file in tqdm(track_names, desc=\"Processing...\"):\n",
    "        str_audiodir = 'data/audio'\n",
    "        str_annodir = 'data/annotations/onsets'\n",
    "        audiodir = os.fsencode(str_audiodir)\n",
    "        refdir = os.fsencode(str_annodir)\n",
    "        audiofile = os.path.join(str_audiodir, file+\".flac\")\n",
    "        annotationsfile = os.path.join(str_annodir, file+\".onsets\")\n",
    "        \n",
    "        # Pipeline:\n",
    "        spec = preprocessing(audiofile=audiofile, sr=sr, preprocessor=preprocessor)\n",
    "        odf = reduction_filtering(log_filtered_spec=spec)\n",
    "        onsets = peak_picking(odf=odf, peakprocessor=peak_proc)\n",
    "        eval_obj = evaluation(onsets=onsets, annotationsfile=annotationsfile)\n",
    "        \n",
    "        # Write evaluation measures to log file\n",
    "        dict_fscores[re.sub('\\.onsets$', '', file)] = round(eval_obj.fmeasure, 2)\n",
    "        #f.write(re.sub('\\.onsets$', '', filename) + \": \" + str(round(eval_obj.fmeasure, 2)) + \"\\n\")\n",
    "        #f.write(\"Precision: \" + str(round(eval_obj.precision, 2)) + \"\\n\")\n",
    "        #f.write(\"Recall:    \" + str(round(eval_obj.recall, 2)) + \"\\n\")\n",
    "        #f.write(\"F-Measure: \" + str(round(eval_obj.fmeasure, 2)) + \"\\n\\n\")\n",
    "        list_evals.append(eval_obj)\n",
    "        \n",
    "    # Evaluation over complete dataset\n",
    "    sum_eval = OnsetSumEvaluation(list_evals)\n",
    "    print(sum_eval)\n",
    "    total_sum_evals.append(sum_eval)\n",
    "        \n",
    "    # Sort results\n",
    "    results_dict = dict(sorted(dict_fscores.items(), key=lambda x:x[1], reverse=True))\n",
    "    df = pd.DataFrame.from_dict(data=results_dict, orient='index', columns=['F-Score'])\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d81e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
